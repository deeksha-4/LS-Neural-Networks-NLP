{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deeksha-4/LS-Neural-Networks-NLP/blob/main/Week1/NN_using_PyTorch_(Graded).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PyTorch Implementation of Neural Networks**\n",
        "In this week's graded assignment, you will implement a neural network that will perform binary classification on a set of images (ie. is or is not).\n",
        "\n",
        "You are to only write/modify the code in between consecutive `# <START>` and `# <END>` comments. DO NOT modify other parts of the notebook, your assignments will not be graded otherwise.\n",
        "\n",
        "```python\n",
        "\"Don't modify any code here\"\n",
        "\n",
        "# <START>\n",
        "\"YOUR CODE GOES HERE!\"\n",
        "# <END>\n",
        "\n",
        "\"Don't modify any code here\"\n",
        "```\n",
        "## **Before you begin**\n",
        "Before you start with the assignment, you will have to upload the images that you will classify to your Google Drive.  \n",
        "You will be able to find the compressed folder named **\"pizza_vs_not\"** on both the GitHub repo and the Week 1 MS Teams channel.  \n",
        "Download the file, unzip it, and then upload it to your Drive.\n",
        "\n",
        "### **Make sure to upload to the same account that you are using on Colab, otherwise you won't be able to access the files**\n"
      ],
      "metadata": {
        "id": "pbwA7e12AVLe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Mounting Google Drive**\n",
        "First, we need to import the dataset of images from your Google Drive. To do so, **run the below cell**. This will mount your Drive to the running Colab instance. Then, you will be able to access all your Google Drive data in this notebook."
      ],
      "metadata": {
        "id": "D0lIe1uahq_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ObnNbRJPQrYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import the Libraries**\n",
        "\n",
        "Run the cell below to import all the necessary libraries for building the neural network using PyTorch.  \n",
        "You will primarily use the **`nn` module** of the **PyTorch** library for building the neural network."
      ],
      "metadata": {
        "id": "ElYLMOGFBq1r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZVxJx87kAAN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importing the Dataset**\n",
        "\n",
        "We now need to import the dataset from the Google Drive. Below given is a function named `getdata`, which takes the path of the folder from which data is to be imported as its argument.\n",
        "\n",
        "You are required to give in the path of the folder in which the images of `pizza` and `not_pizza` are saved in your Google Drive. Locate the path using the Colab File Explorer (the file icon in the sidebar).\n",
        "\n",
        "The `getdata` function reads each image stored at the given path and converts and stores it as a PyTorch Tensor.\n",
        "\n",
        "_Note: This cell may take a while to finish running_\n",
        "<details>\n",
        "  <summary>Hint</summary>\n",
        "  The Google Drive was mounted to the location \"/content/drive\", containing the folder \"My Drive\", which corresponds to your actual Google Drive.\n",
        "</details>"
      ],
      "metadata": {
        "id": "GpoxEmvICmNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getdata(path):\n",
        "  data = torch.tensor([])\n",
        "  file_list = os.listdir(path)\n",
        "  for file_name in file_list[:350]:\n",
        "    image_path = os.path.join(path, file_name)\n",
        "    image = mpimg.imread(image_path)\n",
        "    imageData = torch.from_numpy(image).long()\n",
        "    data = torch.cat((data, imageData.unsqueeze(0)), dim=0)\n",
        "  return data\n",
        "\n",
        "# <START>\n",
        "pizza_path = ''\n",
        "not_pizza_path = ''\n",
        "# <END>\n",
        "\n",
        "not_pizza_data = getdata(not_pizza_path)\n",
        "pizza_data = getdata(pizza_path)"
      ],
      "metadata": {
        "id": "QvO6vf9cqR5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the next cell, you can preview the images you've just loaded"
      ],
      "metadata": {
        "id": "SIucUmRBGaZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change values of index, data\n",
        "# <START>\n",
        "index = 222 # 0 to 349\n",
        "data = not_pizza_data # pizza_data (or) not_pizza_data\n",
        "# <END>\n",
        "\n",
        "plt.imshow(data[index].int())"
      ],
      "metadata": {
        "id": "7a_9TI1zEd7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Preprocessing the dataset**\n",
        "\n",
        "Before we begin working with the neural network, we need to make sure our data (in this case, $64\\times64$ RGB images) is in a format that neural networks can work with.\n",
        "\n",
        "First, we create a `train_data` collection of images for training the neural network, and another collection `test_data` that will then be used to check the accuracy of the trained neural network. We do this by taking slices of the total data and concatenating them.  "
      ],
      "metadata": {
        "id": "uiKp-IkYDpB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = torch.cat((pizza_data[:300], not_pizza_data[:200]), dim = 0)\n",
        "test_data = torch.cat((pizza_data[300:350], not_pizza_data[200:250]), dim = 0)\n",
        "print(train_data.shape)"
      ],
      "metadata": {
        "id": "qHHnTe3Hq8cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each image is still stored as a $64\\times64\\times3$ tensor ie. a $64\\times64$ array of 3 numbers - the RGB values of the pixel, taking values between **0 to 255**.  \n",
        "You need to flatten the images in both datasets to make *reshaped* data, and normalise them to get the *final* data we will use to train and test the model.\n",
        "\n",
        "<details>\n",
        "  <summary>Hint</summary>\n",
        "  Use the reshape command to flatten the dataset and then normalise the flattened dataset (ie. make sure all the values lie between 0 and 1).\n",
        "</details>"
      ],
      "metadata": {
        "id": "gp5rsLIAEBKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <START>\n",
        "\n",
        "reshaped_train_data =\n",
        "reshaped_test_data =\n",
        "\n",
        "final_train_data =\n",
        "final_test_data =\n",
        "\n",
        "# <END>\n",
        "\n",
        "print(final_train_data.shape, final_test_data.shape)"
      ],
      "metadata": {
        "id": "XxdYwPTe3dMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that you have made two datasets, you need to make their corresponding `labels` Tensors, which store the true output for each image (whether or not it is a pizza).\n",
        "\n",
        "In the `labels` Tensor, use **`1`** for images that belong to `pizza` and **`0`** for `not_pizza`. (Try to use the concatenate function instead of simply using *for* loops for generating the `labels` Tensor !!)\n",
        "\n",
        "**Remember** to ensure that both `train_labels` and `test_labels` are 2D tensors of appropriate dimensions. Otherwise, it can cause issues ahead."
      ],
      "metadata": {
        "id": "CN9sZzmAEhed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <START>\n",
        "\n",
        "train_labels =\n",
        "\n",
        "test_labels =\n",
        "\n",
        "# <END>\n",
        "\n",
        "print(train_labels.shape, test_labels.shape)"
      ],
      "metadata": {
        "id": "AB9ngSqaruoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Building the Neural Network**\n",
        "\n",
        "Now, we will start making the actual neural network.\n",
        "\n",
        "First, initialise the hyperparameters of the neural network.  \n",
        "Here, we are going to make a 3 layer neural network (i.e., 1 input layer, 2 hidden layers and 1 output layer). The first hidden layer will have 10 nodes, while the second will have 12.   \n",
        "Enter the number of input parameters, number of nodes of each hidden layer and the number of output parameters."
      ],
      "metadata": {
        "id": "tfcBVaGoFVH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <START>\n",
        "\n",
        "D_in =\n",
        "H1 =\n",
        "H2 =\n",
        "D_out =\n",
        "\n",
        "# <END>"
      ],
      "metadata": {
        "id": "Nzoq4S8aqY88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you will make the actual model. The Model includes the use of `Linear` function at each layer, alongside non-linear activation functions.\n",
        "\n",
        "We are going to use `ReLU` functions as activation functions for the input and the first hidden layer and `Sigmoid` function for the final output, as we want an output between 0 and 1.\n",
        "\n",
        "(Hint: `Linear`, `ReLU` and `Sigmoid` functions are a part of the `nn` module of the **PyTorch** library)"
      ],
      "metadata": {
        "id": "k99hJnXbGAwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = torch.nn.Sequential(\n",
        "    # Do not hard-code any values, use the variables from the previous cell\n",
        "    # <START>\n",
        "\n",
        "    # <END>\n",
        "\n",
        ")\n"
      ],
      "metadata": {
        "id": "YFA7NWqTqdlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(final_train_data[0]) #To check if the model works"
      ],
      "metadata": {
        "id": "nkoOyUiYzTGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After making the model, we defined the `loss_fn` , i.e., the loss function as the Binary Cross Entropy Loss.\n",
        "\n",
        "Here, you will implement gradient descent.\n",
        "\n",
        "The `learning_rate` is the step size which the neural network takes when it updates the parameters of the network. (Try to explore various values of step size. Values similar to 0.005 are usually suitable). Also play around with the number of `iterations` the gradient descent algorithm needs to take.\n",
        "\n",
        "**Follow the steps given as per the comments.**\n",
        "\n",
        "*Note: When you run the code, it could take about 5 minutes for the network to finish training.*"
      ],
      "metadata": {
        "id": "pI5qXU5fHPG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "# <START>\n",
        "\n",
        "learning_rate = 0.005\n",
        "iterations = 10000\n",
        "\n",
        "for t in range(iterations):\n",
        "\n",
        "    # call the model on the dataset\n",
        "    y_pred =\n",
        "\n",
        "    #calculate the loss\n",
        "    loss =\n",
        "\n",
        "    if t%1000 == 1:\n",
        "        print(loss)\n",
        "\n",
        "    #calculate the gradients (dont forget to reset the gradients before you begin)\n",
        "\n",
        "\n",
        "    # update the values of the parameters\n",
        "    with torch.no_grad():\n",
        "\n",
        "# <END>\n",
        "\n",
        "torch.save(model, 'model_best.pt')"
      ],
      "metadata": {
        "id": "WrcyQE-nqgUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Checking the Results**\n",
        "Now that we have used the training set to train the network, we shall use the test set to check how the neural network performs with new inputs."
      ],
      "metadata": {
        "id": "uT_u2Q_EJ4ki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change values of index\n",
        "# <START>\n",
        "index = 0 #0 to 99\n",
        "# <END>\n",
        "\n",
        "plt.imshow(test_data[index].int())\n",
        "print (f'According to the neural network, index = {index} is {\"a pizza\" if model(final_test_data[index]) > 0.5 else \"not a pizza\"}' )"
      ],
      "metadata": {
        "id": "Ykt2FcjfHW0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To quantize how accurately the neural network is able to classify images, we have defined a helper `predict` function that takes a dataset and returns the fraction of times the neural network correctly classified the image.  \n",
        "\n",
        "Complete the function such that it prints the correct accuracy of its predictions."
      ],
      "metadata": {
        "id": "3fQcWl1rHcuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, data, labels):\n",
        "\n",
        "    probabilities = model(data)\n",
        "\n",
        "    # <START>\n",
        "\n",
        "    # generate the predictions tensor using the probabilities variable, which indicates the prediction made by the model for the given data using 0 and 1\n",
        "\n",
        "    predictions =\n",
        "\n",
        "    # <END>\n",
        "\n",
        "    print(\"Accuracy: \"  + str(torch.sum((predictions == labels)).item()/predictions.shape[0]))"
      ],
      "metadata": {
        "id": "RFwT6ARBs7gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the cell below to find out the accuracy of your model for the training and test datasets."
      ],
      "metadata": {
        "id": "7PVdX70uLUY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict(model, final_train_data, train_labels)\n",
        "predict(model,final_test_data,test_labels)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "V_iNzulpYpHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Extra Content (Optional)**\n",
        "##### **These are extra exercises you can try after submitting the assignment, for you to try on your own. Feel free to approach us with any doubts, but DO NOT make these changes to the notebook before you submit**\n",
        "- Try varying things like the number and size of the hidden layers, and seeing how that affects the accuracy of the network.\n",
        "- Along with `pizza` and `not_pizza`, you should see another folder `other_dishes` in the dataset. Try using it in place of `not_pizza`. What changes do you see? Why do you think this happens?"
      ],
      "metadata": {
        "id": "DYae7InELIF6"
      }
    }
  ]
}